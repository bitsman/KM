#+title: 数学 
#+author: 比克曼
#+latex_class: org-latex-pdf 
#+latex: \newpage 

* 代数
** 概念
- 自然数：natural number，{0，1，2，3...}等全体非负整数组成的数的集合称为自然数；
- 正整数：positive integer，{1，2，3...}等向前扩充的数称为正整数；
- 负整数：{1，2，3...}等向后扩充的数称为妇整数；
- 中性数：0被称为中性数；
- 整数： integer，把正整数、负整数、中性数(0)合在一起叫整数，对＋、－、×运算组成一个封闭的数域集合；
- 有理数：rational number，整数对÷不封闭，有理数则在整数基础上对÷封闭的数域，或者可以表示成两个整数之比;
- 无理数：irrational number，不能表示成2个整数之比的数，比如\(\sqrt{2}\)和圆周率；
- 实数：real number，有理数和无理数合到一起称为实数；
- 虚数：imaginary number，符号用i表示，i = \(\sqrt{-1}\)；
- 复数：complex number，由实数和虚数构造出的数叫复数；
- 向量：vector； 
- 矩阵：matrix；
- 张量：tensor；
- 群：group；
- 环：loop；
- 域：field；
- 线性代数：研究未知数更多的一次方程组，引进矩阵、向量、空间等概念形成的方向；
- 多项式代数：研究未知数次数更高的高次方程，形成的方向；
  #+caption: 数的归纳
  #+label: img-number
  #+attr_latex: placement=[H] scale=0.3
  #+begin_src ditaa :file ./img/img-number.png :cmdline -S -E
                                                                                                  +--positive integer
                                                                                                  |
                                                                     +--positive rational number--+
                                                                     |                            |
                                                 +--rational number--+--0                         +--positive fraction
                                                 |                   |                          +--native integer
                                 +--real number--+                   +--native rational number--+
                                 |               |                                              |
                                 |               +--irrational number                           +--native fraction
                                 |
                                 |
          +--generalized number--+
          |                      |
          |                      +--complex number(a+bi)
  number--+
          |                 +--vector
          |                 |
          +--narrow number--+--matrix
                            |
                            +--other(tensor,group,loop,field)
  #+end_src
** 多项式
*** 概念
- 最大公因式：设f(x), g(x)是P[x]中两个多项式。P[x]中多项式d(x)称为f(x), g(x)的一个最大公因式，如果它满足
  1. d(x)是f(x)，g(x)的公因式；
  2. f(x)，g(x) 的公因式全是d(x)的因式；
- 多项式互素：P[x]中两个多项式f(x)，g(x)称为互素(互质)，如果(f(x), g(x))=1;  ((f(x), g(x))表示首项系数是1的最大公因式)；
- 重因式：不可约多项式p(x)称为多项式f(x)的k重因式，如果\(p^{k}x | f(x)\)，而\(p^{k+1}x ! f(x)\); (g(x)|f(x)表示g(x)能整
  除f(x)) ; 
- 多项式微商: 对多项式求导；
- 本原多项式：如果一个非零的整系数多项式\(g(x)=b_{n}x^{n}+b_{n-1}x^{n-1}+……+b_{0}\) 的系数\(b_{n}, b_{n-1}, ……，b_{0}\)
  没有异于±1的公因子，也就说它们是互素的，这个多项式被称为本原多项式；
- 本原多项式定理(高斯引理)：两个本原多项式的乘积还是本原多项式；
- 对称多项式：设\(f(x_{1}, x_{2}, ……, x_{n})\)是数环R上一个n元多项式，如果对于这n个文字\(x_{1}, x_{2}, ……, x_{n}\)的
  指标集{1, 2, ……, n}施行任意置换后，\(f(x_{1}, x_{2}, ……, x_{n})\)都不改变，那么就称\(f(x_{1}, x_{2}, ……, x_{n})\)
  是R上一个n元对称多项式；
*** 满足定律
- 加法交换律, f(x)+g(x)=g(x)+f(x)；
- 加法结合律, (f(x)+g(x))+h(x) = f(x)+(g(x)+h(x)); 
- 乘法交换律, f(x)g(x)=g(x)f(x); 
- 乘法结合律, (f(x)g(x))h(x)=f(x)(g(x)h(x)); 
- 乘法对加法的分配律, f(x)(g(x)+h(x))=f(x)g(x)+f(x)h(x); 
- 乘法消去律, f(x)g(x)=f(x)h(x)且f(x) \(\neq\) 0, 那么g(x)=h(x);
- 任何n(n>0)次多项式在复数域中有n个根(重根按重数计算)
*** 公式
- 多项式乘法，f(x)g(x) = \(\sum_{i=0}^{n}a_{i}x^{i}\) \(\sum_{j=0}^{m}b_{j}x^{j}\) = \(\sum\limits_{s=0}^{m+n}(\sum\limits_{i+j}a_{i}b_{j})x^{s}\)
- 多项式微商：
  1. (f(x)+g(x))' = f'(x) + g'(x);
  2. (cf(x))' = cf'(x);
  3. (f(x)g(x))' = f'(x)g(x) + f(x)g'(x);
  4. \((f^{m}(x))' = mf^{m-1}(x)f'(x)\)
  
*** 应用
***** 多项式拟合
- 概念：根据给定的m个点，并不要求这条曲线经过这些点，而是y=f(x)的近似曲线y=\(\Phi(x)\)；
* 概率
** 概念
- 样本空间：随机试验的所有可能结果组成的集合;
- 随机变量：打靶打入XY坐标系，打入的位置是个二维随机变量(x, y), 随机变量不是一个概率;随机变量分为：
  1. 离散随机变量：只能取有限个值，虽然可以是无穷多的，但是是离散化的；
  2. 连续型随机变量：可以取无穷多的连续值；
- 概率函数：对于随机变量X的概率叫概率函数: $$ p_{i} = P(X = a_{i}), i = 1,...,n $$ 
- 概率分布：概率函数给出了全部概率1是如何在其可能值之间分配的,  _其实可以将概率分布和概率函数等同认识_ ；
- 分布函数： _可以认为是概率函数在区间段的求和_ , 设X为一随机变量，则分布函数为 $$P(X \leq x) = F(x), -\infty < x < \infty$$   
- 概率密度函数：如果对于随机变量X的分布函数F(x),存在非负可积函数f(x)，使对于任意实数x有 
  $$F(x) = \int_{\infty}^{x}f(t)dt $$ 则f(x)称为X的概率密度函数，简称概率密度, 只有在x点处连续，才有f(x)=F'(x)； 
- 等可能概型中事件A的计算公式： $$P(A) = \sum_{j=1}^{k}P({e_{i_{j}}})=\frac{k}{n}=\frac{A包含的基本事件数}{S中基本事件的总数} $$
- 条件概率：事件A已经发生的条件下，事件B发生的概率，表示为$$P(B|A)=\frac{P(AB)}{P(A)}$$
- 互斥时间和的概率：等于各事件概率的和： $P(A_{1}+A_{2}+...+A_{n}) = P(A_{1})+P(A_{2})+...+P(A_{n})$
- 对立事件A的概率：$P(\overline{A}) = 1 - P(A)$
- 独立事件的概率：若干个独立事件 $A_{1},...,A_{n}$ 之积的概率，等于各事件概率的乘积：$P(A_{1}...A_{n}) = P(A_{1})...P(A_{n})$
- 全概率：其意义在于在较复杂的情况下直接计算A事件概率P(A)不容易，但是A事件总是随某个B_{i}发生，则适当去构造这组B_{i}可以简化
  计算。其公式如下，其中用到了条件概率公式, 此公式还能从另一个角度去理解，把B_{i}看做导致事件A发生的一种可能途径，对不同途
  径，A发生的概率即条件概率P(A|B)各不同，而采取哪个途径g却是随机的。 
  $$ P(A)=P(AB_{1})+...+P(AB_{n}) = P(B_{1})P(A|B_{1})+...+P(B_{n})P(A|B_{n}) $$
- 贝叶斯公式：刻画了一些事件B_{i}其原有发生概率在事件A引入的条件下B_{i}的概率发生了改变；如果把事件A看成结果，把诸事件B_{i}看
  成导致结果A的可能原因，则全概率公式可以看做为“由原因推结果”，而贝叶斯公式则相反为“由结果推原因”，现在有结果A已经发
  生了，在众多原因B_{i}中到底由哪个导致，贝叶斯公式可以给出度量，类似于发生了某个案件A，在不了解案情前，嫌疑人B_{i}根据以往
  的记录其作案的概率为P(B_i)，但是如果了解了A案情，则P(B_i)就会变动了；贝叶斯公式用语言表达为，
  $$ 后验概率 = \frac{似然函数因子*先验概率}{证据因子}$$ 
  贝叶斯公式如下：设试验E的样本空间为S，A为E的事件，B_{i}为S的一个划分，且P(A)>0, P(B_{i})>0, 则A事件发生情况下，A来自
  B_{i}划分的概率为 $$P(B_{i}|A) = \frac{P(AB_{i})}{P(A)} = \frac{P(B_{i})P(A|B_{i})}{\sum_{j}P(B_{j})P(A|B_{j})}$$
- 先验概率：一般从原因推结果的论证称为先验的, 如果一个事件(W)发生的原因(a_{ij})有很多，则P(W)叫先验概率, 通常是我们在没
  有分析这些原因前根据自己的经验决定的概率，P(W|a_{ij})叫后验概率，在分析原因后对结果概率做的修正概率; 
- 后验概率：一般从结果推原因的论证称为后验的，以堵车为例，堵车的原因假定有车辆太多和交通事故，堵车的概率可以按照以往的经
  验得到，这个概率就是先验概率，那若出门前听到新闻说今天路上出现了交通事故，然后我们计算堵车的概率，这个就是条件概率即
  P(堵车|交通事故)，这是由因求果，或者在出门前我们知道了路上发生了交通事故，并且车辆很多，然后计算堵车的概率，这下就要用
  全概率公式计算；如果我们已经出门，出现了堵车，那么我们想计算这次堵车由交通事故引起的概率是多少，就是后验概率，也可以说
  是条件概率，P(交通事故|堵车)，这是由果求因；
- 算术平均值：算术平均值是期望值的无偏估计量；
  $$ \overline{x} = \frac{x_{1}+...+x_{n}}{n} = \frac{\sum_{i=1}^{n}x_{i}}{n}$$
- 均方根平均值： $$ \overline{x}=\sqrt{\frac{x_{1}^{2}+...+x_{n}^{2}}{n}}=\sqrt{\frac{\sum_{i=1}^{n}x_{i}^{2}}{n}}$$
- 几何平均值： $$ \overline{x}=\sqrt[n]{x_{1}*...*x_{n}}=\sqrt[n]{\prod_{i=1}^{n}x_{i}}$$
- 对数平均值: $$ \overline{x}=\frac{x_{1}-x_{2}}{\ln{x_{1}-\ln{x_{2}}}}$$
- 加权平均值： $$ \overline{x}=\frac{w_{1}x_{1}+...+w_{n}x_{n}}{w_{1}+...+w_{n}}=\frac{\sum{w_{i}x_{i}}}{\sum{w_{i}}}$$ 
- 期望值：也称均值，$\overline{X} = \frac{\sum_{i=1}^{n} X_{i}}{n}$, 如果知道每个点x的概率f(x)，则可以写为 $E(X) = \sum
  x_{k}f(x_{x})$, 描述的是样本集合的中间点，平均值；
- 方差：标准差为方差的开方，令u=E(X)为均值，定义X的方差Var(X)=E((X-u)^2)=E(X^2)-u^2, 另外还可以这样计算，方差
  $V^{2}=\frac{\sum_{i=1}^{n}(X_{i}-\overline{X})}{n-1}$ , 描述了各个点x相对于均值的离散度；
- 协方差：期望值和方差一般用来描述一维的数据，但是当两个,多个随机变量可能存在一定关系时, 比如男孩的猥琐程度和受女孩子喜
  欢的程度，就需要协方差来衡量，方差只可能为非负，但是协方差可以为正、0、负，从而引出了正相关、相互独立、负相关，如果协
  方差为正，代表男孩越猥琐越受欢迎，如果为负代表男孩越猥琐越不受欢迎，如果为0代表两者无关。协方差的定义公式类似方差
  $cov(X,Y) = \frac{\sum_{i=1}^{n}(X_{i}-\overline{X})(Y_{i}-\overline{Y})}{n-1}$; 如果面对多维的情况时，协方差也没法独
  自描述，这时就需要协方差矩阵进行描述矩阵的元素为两两随机变量的协方差，比如数据集有{x，y，z}三个维度情况; 
#<<math-relevance>>
- 总体线性相关系数: X和Y的总体线性相关系数,其中Var(X)，Var(Y)为X,Y的方差，Cov(X, Y)为X和Y的协方差； 
  $$ \rho = \frac{Cov(X,Y)}{\sqrt{Var(X)Var(Y)}}$$
- 样本线性相关系数: X和Y的样本线性相关系数，其中X_{i}和Y_{i}分别是变量X和Y的样本观测值， $\overline{X}, \overline{Y}$ 分别是
  变量X和Y样本值的平均值；
  $$ r_{XY}=\frac{\sum(X_{i}-\overline{X})(Y_{i}-\overline{Y})}{\sqrt{\sum(X_{i}-\overline{X})^{2}\sum(Y_{i}-\overline{Y})^{2}}}$$
- 条件分布：当被解释量X取某固定值时(条件)，Y的值不确定，Y的不同取值形成一定的分布，这就是Y的分布；
- 条件概率：X取某固定值时，Y取不同值的概率称为条件概率；
- 条件期望：对于X的每个取值，对Y所形成的分布确定其期望或者均值，称为Y的条件期望或条件均值，用E(Y|X_i)表示, 见图\ref{img-cond-exp}所示；
- 回归线：对于每个X的取值X_{i}, 都有Y的条件期望E(Y|X_i)与之对应，代表Y的条件期望的点的轨迹形成的直线或者曲线称为回归线, 见
  图\ref{img-cond-exp}所示；
  #+label: img-cond-exp
  #+attr_latex: placement=[H]
  [[./img/cond-exp-plot.jpg]]
- 回归函数：被解释变量Y的条件期望E(Y|X_i)随解释变量X的变化而有规律的变化，如果把Y的条件期望表现为X的如下函数，这个函数称
  为回归函数, 回归函数又分为总体回归函数和样本回归函数；$$ E(Y|X_{i}) = f(X_{i})$$
- 残差：也叫剩余值，residual，表示实际值Y与回归线上的估计值Y'的纵向距离Y-Y', 一般Y'用E(Y)；
- 无偏估计：用期望值来阐述，对于一个总体空间的期望值为U，由于各种原因没办法或者不方便获得这个期望值参数U，但是我们可以通
  过总体空间的一个样本空间的u来估计总体空间的U，一般情况下u是不等于U的，但是总体空间可以划分出若干多个样本空间，也就可以
  获得多个u，对于这么多个u，其实也是一个随机变量，如果这个随机变量的期望值等于总体空间的U，则可以说对我们划分的样本空间，
  可以对总体空间的期望值做无偏估计；官方语言组织叫，参数的样本估计值的期望值等于参数的真实值。估计量的数学期望等于被估计
  参数，则称此为无偏估计 ；
** 排列组合
- 排列：n个相异事物取r个(1<=r<=n)的不同排列总数，为 $P_{r}^{n} = n(n-1)(n-2)...(n-r+1)$ , 如果r=n，则 $P_{r}^{r} = r!$
- 组合：n个相异物件取r个(1<=r<=n)的不同组合总数，为 $C_{r}^{n}=\frac{P_{r}^{n}}{r!}=\frac{n!}{r!(n-r)!}$
- 0!=1; 
** 概率分布
*** 离散分布
**** 01分布
随机变量X只能取0和1两个值，取0和1的概率分布是p，q，p+q=1
**** 二项分布
- 定义：服从二项分布的随机变量X表示在n个独立的是/非试验中成功的次数i，其中每次试验的成功概率为p
  $$ p_{i} = C_{n}^{i}p^{i}(1-p)^{n-i},i=0, 1, ..., n $$
***** python实现
#+begin_src python
from scipy import stats         #倒入工具包
import numpy as np
import matplotlib.pyplot as plt
# ...........................
n = 20                          #定义试验次数
p = 0.3                         #定义每次事件的概率
k = np.arange(21)               #模拟多次试验，事件发生的所有次数
binomial = stats.binom.pmf(k, n, p) #计算每个次数的概率
# ...........................
plt.plot(k, binomial, 'o-')     #将每个次数的概率通过图形表示出来
plt.title('binomial:n=%i, p=%.2f' %(n,p)) #设置标题
plt.xlabel('k times')           #x轴是次数
plt.ylabel('probability of k')  #y轴是k次的概率
plt.show()                      #显示出来
#+end_src

**** 伯努利分布
**** 泊松分布
**** 几何分布
*** 连续分布
**** 正太分布
**** 指数分布
**** \beta分布
  

