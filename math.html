<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
               "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en">
<head>
<title>数学 </title>
<meta http-equiv="Content-Type" content="text/html;charset=utf-8"/>
<meta name="title" content="数学 "/>
<meta name="generator" content="Org-mode"/>
<meta name="generated" content="2015-11-19 17:46:42 中国标准时间"/>
<meta name="author" content="比克曼"/>
<meta name="description" content=""/>
<meta name="keywords" content=""/>
<link rel='stylesheet' type='text/css' href='css/org-manual.css' />
<script type="text/javascript">
<!--/*--><![CDATA[/*><!--*/
 function CodeHighlightOn(elem, id)
 {
   var target = document.getElementById(id);
   if(null != target) {
     elem.cacheClassElem = elem.className;
     elem.cacheClassTarget = target.className;
     target.className = "code-highlighted";
     elem.className   = "code-highlighted";
   }
 }
 function CodeHighlightOff(elem, id)
 {
   var target = document.getElementById(id);
   if(elem.cacheClassElem)
     elem.className = elem.cacheClassElem;
   if(elem.cacheClassTarget)
     target.className = elem.cacheClassTarget;
 }
/*]]>*///-->
</script>
<script type="text/javascript" src="http://orgmode.org/mathjax/MathJax.js">
<!--/*--><![CDATA[/*><!--*/
    MathJax.Hub.Config({
        // Only one of the two following lines, depending on user settings
        // First allows browser-native MathML display, second forces HTML/CSS
        //  config: ["MMLorHTML.js"], jax: ["input/TeX"],
            jax: ["input/TeX", "output/HTML-CSS"],
        extensions: ["tex2jax.js","TeX/AMSmath.js","TeX/AMSsymbols.js",
                     "TeX/noUndefined.js"],
        tex2jax: {
            inlineMath: [ ["\\(","\\)"] ],
            displayMath: [ ['$$','$$'], ["\\[","\\]"], ["\\begin{displaymath}","\\end{displaymath}"] ],
            skipTags: ["script","noscript","style","textarea","pre","code"],
            ignoreClass: "tex2jax_ignore",
            processEscapes: false,
            processEnvironments: true,
            preview: "TeX"
        },
        showProcessingMessages: true,
        displayAlign: "center",
        displayIndent: "2em",

        "HTML-CSS": {
             scale: 100,
             availableFonts: ["STIX","TeX"],
             preferredFont: "TeX",
             webFont: "TeX",
             imageFont: "TeX",
             showMathMenu: true,
        },
        MMLorHTML: {
             prefer: {
                 MSIE:    "MML",
                 Firefox: "MML",
                 Opera:   "HTML",
                 other:   "HTML"
             }
        }
    });
/*]]>*///-->
</script>
</head>
<body>

<div id="preamble">

</div>

<div id="content">
<h1 class="title">数学 </h1>


<div id="table-of-contents">
<h2>Table of Contents</h2>
<div id="text-table-of-contents">
<ul>
<li><a href="#sec-1">代数</a>
<ul>
<li><a href="#sec-1-1">概念</a></li>
<li><a href="#sec-1-2">多项式</a>
<ul>
<li><a href="#sec-1-2-1">概念</a></li>
<li><a href="#sec-1-2-2">满足定律</a></li>
<li><a href="#sec-1-2-3">公式</a></li>
<li><a href="#sec-1-2-4">应用</a></li>
</ul></li>
</ul>
</li>
<li><a href="#sec-2">矩阵</a>
<ul>
<li><a href="#sec-2-1">概念</a></li>
</ul>
</li>
<li><a href="#sec-3">概率</a>
<ul>
<li><a href="#sec-3-1">概念</a></li>
<li><a href="#sec-3-2">排列组合</a></li>
<li><a href="#sec-3-3">概率分布</a>
<ul>
<li><a href="#sec-3-3-1">离散分布</a>
<ul>
<li><a href="#sec-3-3-1-1">01分布</a></li>
<li><a href="#sec-3-3-1-2">二项分布</a></li>
<li><a href="#sec-3-3-1-3">伯努利分布</a></li>
<li><a href="#sec-3-3-1-4">泊松分布</a></li>
<li><a href="#sec-3-3-1-5">几何分布</a></li>
</ul>
</li>
<li><a href="#sec-3-3-2">连续分布</a>
<ul>
<li><a href="#sec-3-3-2-1">正太分布</a></li>
<li><a href="#sec-3-3-2-2">指数分布</a></li>
<li><a href="#sec-3-3-2-3">&beta;分布</a></li>
</ul></li>
</ul></li>
</ul>
</li>
<li><a href="#sec-4">统计</a>
<ul>
<li><a href="#sec-4-1">概念</a></li>
<li><a href="#sec-4-2">贝叶斯分类</a>
<ul>
<li><a href="#sec-4-2-1">最小错误率贝叶斯分类器</a></li>
<li><a href="#sec-4-2-2">最大似然比贝叶斯分类器</a></li>
<li><a href="#sec-4-2-3">最小风险贝叶斯分类器</a></li>
<li><a href="#sec-4-2-4">朴素贝叶斯</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</div>
</div>

<div id="outline-container-1" class="outline-2">
<h2 id="sec-1">代数</h2>
<div class="outline-text-2" id="text-1">


</div>

<div id="outline-container-1-1" class="outline-3">
<h3 id="sec-1-1">概念</h3>
<div class="outline-text-3" id="text-1-1">

<ul>
<li>自然数：natural number，{0，1，2，3&hellip;}等全体非负整数组成的数的集合称为自然数；
</li>
<li>正整数：positive integer，{1，2，3&hellip;}等向前扩充的数称为正整数；
</li>
<li>负整数：{1，2，3&hellip;}等向后扩充的数称为妇整数；
</li>
<li>中性数：0被称为中性数；
</li>
<li>整数： integer，把正整数、负整数、中性数(0)合在一起叫整数，对＋、－、×运算组成一个封闭的数域集合；
</li>
<li>有理数：rational number，整数对÷不封闭，有理数则在整数基础上对÷封闭的数域，或者可以表示成两个整数之比;
</li>
<li>无理数：irrational number，不能表示成2个整数之比的数，比如\(\sqrt{2}\)和圆周率；
</li>
<li>实数：real number，有理数和无理数合到一起称为实数；
</li>
<li>虚数：imaginary number，符号用i表示，i = \(\sqrt{-1}\)；
</li>
<li>复数：complex number，由实数和虚数构造出的数叫复数；
</li>
<li>向量：vector； 
</li>
<li>矩阵：matrix；
</li>
<li>张量：tensor；
</li>
<li>群：group；
</li>
<li>环：loop；
</li>
<li>域：field；
</li>
<li>线性代数：研究未知数更多的一次方程组，引进矩阵、向量、空间等概念形成的方向；
</li>
<li>多项式代数：研究未知数次数更高的高次方程，形成的方向；



<div id="img-number" class="figure">
<p><img src="./img/img-number.png"  alt="./img/img-number.png" /></p>
<p>数的归纳</p>
</div>

</li>
</ul>

</div>

</div>

<div id="outline-container-1-2" class="outline-3">
<h3 id="sec-1-2">多项式</h3>
<div class="outline-text-3" id="text-1-2">


</div>

<div id="outline-container-1-2-1" class="outline-4">
<h4 id="sec-1-2-1">概念</h4>
<div class="outline-text-4" id="text-1-2-1">

<ul>
<li>最大公因式：设f(x), g(x)是P[x]中两个多项式。P[x]中多项式d(x)称为f(x), g(x)的一个最大公因式，如果它满足
<ol>
<li>d(x)是f(x)，g(x)的公因式；
</li>
<li>f(x)，g(x) 的公因式全是d(x)的因式；
</li>
</ol>

</li>
<li>多项式互素：P[x]中两个多项式f(x)，g(x)称为互素(互质)，如果(f(x), g(x))=1;  ((f(x), g(x))表示首项系数是1的最大公因式)；
</li>
<li>重因式：不可约多项式p(x)称为多项式f(x)的k重因式，如果\(p^{k}x | f(x)\)，而\(p^{k+1}x ! f(x)\); (g(x)|f(x)表示g(x)能整
  除f(x)) ; 
</li>
<li>多项式微商: 对多项式求导；
</li>
<li>本原多项式：如果一个非零的整系数多项式\(g(x)=b_{n}x^{n}+b_{n-1}x^{n-1}+……+b_{0}\) 的系数\(b_{n}, b_{n-1}, ……，b_{0}\)
  没有异于±1的公因子，也就说它们是互素的，这个多项式被称为本原多项式；
</li>
<li>本原多项式定理(高斯引理)：两个本原多项式的乘积还是本原多项式；
</li>
<li>对称多项式：设\(f(x_{1}, x_{2}, ……, x_{n})\)是数环R上一个n元多项式，如果对于这n个文字\(x_{1}, x_{2}, ……, x_{n}\)的
  指标集{1, 2, ……, n}施行任意置换后，\(f(x_{1}, x_{2}, ……, x_{n})\)都不改变，那么就称\(f(x_{1}, x_{2}, ……, x_{n})\)
  是R上一个n元对称多项式；
</li>
</ul>

</div>

</div>

<div id="outline-container-1-2-2" class="outline-4">
<h4 id="sec-1-2-2">满足定律</h4>
<div class="outline-text-4" id="text-1-2-2">

<ul>
<li>加法交换律, f(x)+g(x)=g(x)+f(x)；
</li>
<li>加法结合律, (f(x)+g(x))+h(x) = f(x)+(g(x)+h(x)); 
</li>
<li>乘法交换律, f(x)g(x)=g(x)f(x); 
</li>
<li>乘法结合律, (f(x)g(x))h(x)=f(x)(g(x)h(x)); 
</li>
<li>乘法对加法的分配律, f(x)(g(x)+h(x))=f(x)g(x)+f(x)h(x); 
</li>
<li>乘法消去律, f(x)g(x)=f(x)h(x)且f(x) \(\neq\) 0, 那么g(x)=h(x);
</li>
<li>任何n(n&gt;0)次多项式在复数域中有n个根(重根按重数计算)
</li>
</ul>

</div>

</div>

<div id="outline-container-1-2-3" class="outline-4">
<h4 id="sec-1-2-3">公式</h4>
<div class="outline-text-4" id="text-1-2-3">

<ul>
<li>多项式乘法，f(x)g(x) = \(\sum_{i=0}^{n}a_{i}x^{i}\) \(\sum_{j=0}^{m}b_{j}x^{j}\) = \(\sum\limits_{s=0}^{m+n}(\sum\limits_{i+j}a_{i}b_{j})x^{s}\)
</li>
<li>多项式微商：
<ol>
<li>(f(x)+g(x))' = f'(x) + g'(x);
</li>
<li>(cf(x))' = cf'(x);
</li>
<li>(f(x)g(x))' = f'(x)g(x) + f(x)g'(x);
</li>
<li>\((f^{m}(x))' = mf^{m-1}(x)f'(x)\)
</li>
</ol>

</li>
</ul>


</div>

</div>

<div id="outline-container-1-2-4" class="outline-4">
<h4 id="sec-1-2-4">应用</h4>
<div class="outline-text-4" id="text-1-2-4">

<ul>
<li id="sec-1-2-4-1">多项式拟合<br/>
<ul>
<li>概念：根据给定的m个点，并不要求这条曲线经过这些点，而是y=f(x)的近似曲线y=\(\Phi(x)\)；
</li>
</ul>

</li>
</ul>
</div>
</div>
</div>

</div>

<div id="outline-container-2" class="outline-2">
<h2 id="sec-2">矩阵</h2>
<div class="outline-text-2" id="text-2">


</div>

<div id="outline-container-2-1" class="outline-3">
<h3 id="sec-2-1">概念</h3>
<div class="outline-text-3" id="text-2-1">

<ul>
<li>范数：设V是实数域R(或复数域C)上的n维线性空间，对于V中的任意一个向量或矩阵 &alpha; 按照某一确定法则对应着一个实数，这个
  实数称为 &alpha; 的 <span style="text-decoration:underline;">范数</span> , 记为||&alpha;||，几范数就是元素几次方的和，除以维数；
</li>
</ul>

</div>
</div>

</div>

<div id="outline-container-3" class="outline-2">
<h2 id="sec-3">概率</h2>
<div class="outline-text-2" id="text-3">


</div>

<div id="outline-container-3-1" class="outline-3">
<h3 id="sec-3-1">概念</h3>
<div class="outline-text-3" id="text-3-1">

<ul>
<li>样本空间：随机试验的所有可能结果组成的集合;
</li>
<li>随机变量：打靶打入XY坐标系，打入的位置是个二维随机变量(x, y), 随机变量不是一个概率;随机变量分为：
<ol>
<li>离散随机变量：只能取有限个值，虽然可以是无穷多的，但是是离散化的；
</li>
<li>连续型随机变量：可以取无穷多的连续值；
</li>
</ol>

</li>
<li>概率函数：对于随机变量X的概率叫概率函数: $$ p_{i} = P(X = a_{i}), i = 1,...,n $$ 
</li>
<li>概率分布：概率函数给出了全部概率1是如何在其可能值之间分配的,  <span style="text-decoration:underline;">其实可以将概率分布和概率函数等同认识</span> ；
</li>
<li>分布函数： <span style="text-decoration:underline;">可以认为是概率函数在区间段的求和</span> , 设X为一随机变量，则分布函数为 $$P(X \leq x) = F(x), -\infty &lt; x &lt; \infty$$   
</li>
<li>概率密度函数：如果对于随机变量X的分布函数F(x),存在非负可积函数f(x)，使对于任意实数x有 
  $$F(x) = \int_{\infty}^{x}f(t)dt $$ 则f(x)称为X的概率密度函数，简称概率密度, 只有在x点处连续，才有f(x)=F'(x)； 
</li>
<li>等可能概型中事件A的计算公式： $$P(A) = \sum_{j=1}^{k}P({e_{i_{j}}})=\frac{k}{n}=\frac{A包含的基本事件数}{S中基本事件的总数} $$
</li>
<li>条件概率：事件A已经发生的条件下，事件B发生的概率，表示为$$P(B|A)=\frac{P(AB)}{P(A)}$$
</li>
<li>互斥时间和的概率：等于各事件概率的和： \(P(A_{1}+A_{2}+...+A_{n}) = P(A_{1})+P(A_{2})+...+P(A_{n})\)
</li>
<li>对立事件A的概率：\(P(\overline{A}) = 1 - P(A)\)
</li>
<li>独立事件的概率：若干个独立事件 \(A_{1},...,A_{n}\) 之积的概率，等于各事件概率的乘积：\(P(A_{1}...A_{n}) = P(A_{1})...P(A_{n})\)
</li>
<li>全概率：其意义在于在较复杂的情况下直接计算A事件概率P(A)不容易，但是A事件总是随某个B<sub>i</sub>发生，则适当去构造这组B<sub>i</sub>可以简化
  计算。其公式如下，其中用到了条件概率公式, 此公式还能从另一个角度去理解，把B<sub>i</sub>看做导致事件A发生的一种可能途径，对不同途
  径，A发生的概率即条件概率P(A|B)各不同，而采取哪个途径g却是随机的。 
  $$ P(A)=P(AB_{1})+...+P(AB_{n}) = P(B_{1})P(A|B_{1})+...+P(B_{n})P(A|B_{n}) $$
</li>
<li>贝叶斯公式：刻画了一些事件B<sub>i</sub>其原有发生概率在事件A引入的条件下B<sub>i</sub>的概率发生了改变；如果把事件A看成结果，把诸事件B<sub>i</sub>看
  成导致结果A的可能原因，则全概率公式可以看做为“由原因推结果”，而贝叶斯公式则相反为“由结果推原因”，现在有结果A已经发
  生了，在众多原因B<sub>i</sub>中到底由哪个导致，贝叶斯公式可以给出度量，类似于发生了某个案件A，在不了解案情前，嫌疑人B<sub>i</sub>根据以往
  的记录其作案的概率为P(B<sub>i</sub>)，但是如果了解了A案情，则P(B<sub>i</sub>)就会变动了；贝叶斯公式用语言表达为，
  $$ 后验概率 = \frac{似然函数因子*先验概率}{证据因子}$$ 或者 $$ P(原因i|结果) = \frac{P(结果|原因i)*P(原因i)}{P(结果)}$$ 
  贝叶斯公式如下：设试验E的样本空间为S，A为E的事件，B<sub>i</sub>为S的一个划分，且P(A)&gt;0, P(B<sub>i</sub>)&gt;0, 则A事件发生情况下，A来自
  B<sub>i</sub>划分的概率如下公式，其中P(B<sub>i</sub>)可以通过训练集中各个样本所在的比例来估计，而P(A|B<sub>i</sub>)需要做估计，一般分为
<ol>
<li>参数估计：是先假定P(A|B<sub>i</sub>)已经具有某确定的分布形式，比如正太，再用已经具有类别标签的训练集对概率分布的参数进行估
     计；
</li>
<li>非参数估计：非参数是在不知道或者不假设类条件概率密度的分布形式的基础上，直接用样本集中所包含的信息来估计样本的概率
     分布情况。 
</li>
</ol>

<p>  $$P(B_{i}|A) = \frac{P(AB_{i})}{P(A)} = \frac{P(B_{i})P(A|B_{i})}{\sum_{j}P(B_{j})P(A|B_{j})}$$
</p></li>
<li>先验概率：一般从原因推结果的论证称为先验的, 如果一个事件(W)发生的原因(a<sub>ij</sub>)有很多，则P(W)叫先验概率, 通常是我们在没
  有分析这些原因前根据自己的经验决定的概率，P(W|a<sub>ij</sub>)叫后验概率，在分析原因后对结果概率做的修正概率; 
</li>
<li>后验概率：一般从结果推原因的论证称为后验的，以堵车为例，堵车的原因假定有车辆太多和交通事故，堵车的概率可以按照以往的经
  验得到，这个概率就是先验概率，那若出门前听到新闻说今天路上出现了交通事故，然后我们计算堵车的概率，这个就是条件概率即
  P(堵车|交通事故)，这是由因求果，或者在出门前我们知道了路上发生了交通事故，并且车辆很多，然后计算堵车的概率，这下就要用
  全概率公式计算；如果我们已经出门，出现了堵车，那么我们想计算这次堵车由交通事故引起的概率是多少，就是后验概率，也可以说
  是条件概率，P(交通事故|堵车)，这是由果求因；
</li>
<li>期望值：也称均值，\(\overline{X} = \frac{\sum_{i=1}^{n} X_{i}}{n}\), 如果知道每个点x的概率f(x)，则可以写为 \(E(X) = \sum
  x_{k}f(x_{x})\), 描述的是样本集合的中间点，平均值；
</li>
<li>方差：标准差为方差的开方，令u=E(X)为均值，定义X的方差Var(X)=E((X-u)<sup>2</sup>)=E(X<sup>2</sup>)-u<sup>2</sup>, 另外还可以这样计算，方差
  \(V^{2}=\frac{\sum_{i=1}^{n}(X_{i}-\overline{X})}{n-1}\) , 描述了各个点x相对于均值的离散度；
</li>
<li>协方差：期望值和方差一般用来描述一维的数据，但是当两个,多个随机变量可能存在一定关系时, 比如男孩的猥琐程度和受女孩子喜
  欢的程度，就需要协方差来衡量，方差只可能为非负，但是协方差可以为正、0、负，从而引出了正相关、相互独立、负相关，如果协
  方差为正，代表男孩越猥琐越受欢迎，如果为负代表男孩越猥琐越不受欢迎，如果为0代表两者无关。协方差的定义公式类似方差
  \(cov(X,Y) = \frac{\sum_{i=1}^{n}(X_{i}-\overline{X})(Y_{i}-\overline{Y})}{n-1}\); 如果面对多维的情况时，协方差也没法独
  自描述，这时就需要协方差矩阵进行描述矩阵的元素为两两随机变量的协方差，比如数据集有{x，y，z}三个维度情况; 
</li>
</ul>

<p><a name="math-relevance" id="math-relevance"></a>
</p><ul>
<li>总体线性相关系数: X和Y的总体线性相关系数,其中Var(X)，Var(Y)为X,Y的方差，Cov(X, Y)为X和Y的协方差； 
  $$ \rho = \frac{Cov(X,Y)}{\sqrt{Var(X)Var(Y)}}$$
</li>
<li>样本线性相关系数: X和Y的样本线性相关系数，其中X<sub>i</sub>和Y<sub>i</sub>分别是变量X和Y的样本观测值， \(\overline{X}, \overline{Y}\) 分别是
  变量X和Y样本值的平均值；
  $$ r_{XY}=\frac{\sum(X_{i}-\overline{X})(Y_{i}-\overline{Y})}{\sqrt{\sum(X_{i}-\overline{X})^{2}\sum(Y_{i}-\overline{Y})^{2}}}$$
</li>
<li>条件分布：当被解释量X取某固定值时(条件)，Y的值不确定，Y的不同取值形成一定的分布，这就是Y的分布；
</li>
<li>条件概率：X取某固定值时，Y取不同值的概率称为条件概率；
</li>
<li>条件期望：对于X的每个取值，对Y所形成的分布确定其期望或者均值，称为Y的条件期望或条件均值，用E(Y|X<sub>i</sub>)表示, 见图<a href="#img-cond-exp">img-cond-exp</a>所示；
</li>
<li>回归线：对于每个X的取值X<sub>i</sub>, 都有Y的条件期望E(Y|X<sub>i</sub>)与之对应，代表Y的条件期望的点的轨迹形成的直线或者曲线称为回归线, 见
  图<a href="#img-cond-exp">img-cond-exp</a>所示；
  <img src="./img/cond-exp-plot.jpg"  alt="./img/cond-exp-plot.jpg" />
</li>
<li>回归函数：被解释变量Y的条件期望E(Y|X<sub>i</sub>)随解释变量X的变化而有规律的变化，如果把Y的条件期望表现为X的如下函数，这个函数称
  为回归函数, 回归函数又分为总体回归函数和样本回归函数；$$ E(Y|X_{i}) = f(X_{i})$$
</li>
<li>无偏估计：用期望值来阐述，对于一个总体空间的期望值为U，由于各种原因没办法或者不方便获得这个期望值参数U，但是我们可以通
  过总体空间的一个样本空间的u来估计总体空间的U，一般情况下u是不等于U的，但是总体空间可以划分出若干多个样本空间，也就可以
  获得多个u，对于这么多个u，其实也是一个随机变量，如果这个随机变量的期望值等于总体空间的U，则可以说对我们划分的样本空间，
  可以对总体空间的期望值做无偏估计；官方语言组织叫，参数的样本估计值的期望值等于参数的真实值。估计量的数学期望等于被估计
  参数，则称此为无偏估计 ；
</li>
</ul>

</div>

</div>

<div id="outline-container-3-2" class="outline-3">
<h3 id="sec-3-2">排列组合</h3>
<div class="outline-text-3" id="text-3-2">

<ul>
<li>排列：n个相异事物取r个(1&lt;=r&lt;=n)的不同排列总数，为 \(P_{r}^{n} = n(n-1)(n-2)...(n-r+1)\) , 如果r=n，则 \(P_{r}^{r} = r!\)
</li>
<li>组合：n个相异物件取r个(1&lt;=r&lt;=n)的不同组合总数，为 \(C_{r}^{n}=\frac{P_{r}^{n}}{r!}=\frac{n!}{r!(n-r)!}\)
</li>
<li>0!=1; 
</li>
</ul>

</div>

</div>

<div id="outline-container-3-3" class="outline-3">
<h3 id="sec-3-3">概率分布</h3>
<div class="outline-text-3" id="text-3-3">


</div>

<div id="outline-container-3-3-1" class="outline-4">
<h4 id="sec-3-3-1">离散分布</h4>
<div class="outline-text-4" id="text-3-3-1">


</div>

<div id="outline-container-3-3-1-1" class="outline-5">
<h5 id="sec-3-3-1-1">01分布</h5>
<div class="outline-text-5" id="text-3-3-1-1">

<p>随机变量X只能取0和1两个值，取0和1的概率分布是p，q，p+q=1
</p></div>

</div>

<div id="outline-container-3-3-1-2" class="outline-5">
<h5 id="sec-3-3-1-2">二项分布</h5>
<div class="outline-text-5" id="text-3-3-1-2">

<ul>
<li>定义：服从二项分布的随机变量X表示在n个独立的是/非试验中成功的次数i，其中每次试验的成功概率为p
  $$ p_{i} = C_{n}^{i}p^{i}(1-p)^{n-i},i=0, 1, ..., n $$
</li>
</ul>

<ul>
<li id="sec-3-3-1-2-1">python实现<br/>



<pre class="example">from scipy import stats         #倒入工具包
import numpy as np
import matplotlib.pyplot as plt
# ...........................
n = 20                          #定义试验次数
p = 0.3                         #定义每次事件的概率
k = np.arange(21)               #模拟多次试验，事件发生的所有次数
binomial = stats.binom.pmf(k, n, p) #计算每个次数的概率
# ...........................
plt.plot(k, binomial, 'o-')     #将每个次数的概率通过图形表示出来
plt.title('binomial:n=%i, p=%.2f' %(n,p)) #设置标题
plt.xlabel('k times')           #x轴是次数
plt.ylabel('probability of k')  #y轴是k次的概率
plt.show()                      #显示出来
</pre>


</li>
</ul>
</div>

</div>

<div id="outline-container-3-3-1-3" class="outline-5">
<h5 id="sec-3-3-1-3">伯努利分布</h5>
<div class="outline-text-5" id="text-3-3-1-3">

</div>

</div>

<div id="outline-container-3-3-1-4" class="outline-5">
<h5 id="sec-3-3-1-4">泊松分布</h5>
<div class="outline-text-5" id="text-3-3-1-4">

</div>

</div>

<div id="outline-container-3-3-1-5" class="outline-5">
<h5 id="sec-3-3-1-5">几何分布</h5>
<div class="outline-text-5" id="text-3-3-1-5">

</div>
</div>

</div>

<div id="outline-container-3-3-2" class="outline-4">
<h4 id="sec-3-3-2">连续分布</h4>
<div class="outline-text-4" id="text-3-3-2">


</div>

<div id="outline-container-3-3-2-1" class="outline-5">
<h5 id="sec-3-3-2-1">正太分布</h5>
<div class="outline-text-5" id="text-3-3-2-1">

<ul>
<li>概率密度：设连续型随机变量X具有概率密度如下，则称X服从参数为\(\mu, \sigma\)的正态分布，记为\(N(\mu, \sigma^{2})\)
  $$ p(x) = \frac{1}{\sqrt{2\pi}\sigma}e^{-\frac{(x-\mu)^{2}}{2\sigma^{2}}}, -\infty&lt;x&lt;\infty $$
</li>
<li>分布函数： $$ F(x)=\frac{1}{\sqrt{2\pi}\sigma}\int_{-\infty}^{x}e^{-\frac{(t-\mu)^{2}}{2\sigma^{2}}}\mathrm{d}t$$ 
</li>
</ul>

</div>

</div>

<div id="outline-container-3-3-2-2" class="outline-5">
<h5 id="sec-3-3-2-2">指数分布</h5>
<div class="outline-text-5" id="text-3-3-2-2">

</div>

</div>

<div id="outline-container-3-3-2-3" class="outline-5">
<h5 id="sec-3-3-2-3">&beta;分布</h5>
<div class="outline-text-5" id="text-3-3-2-3">

</div>
</div>
</div>
</div>

</div>

<div id="outline-container-4" class="outline-2">
<h2 id="sec-4">统计</h2>
<div class="outline-text-2" id="text-4">


</div>

<div id="outline-container-4-1" class="outline-3">
<h3 id="sec-4-1">概念</h3>
<div class="outline-text-3" id="text-4-1">

<ul>
<li>样本分类：样本具有特征向量，样本属于某个类别，如果在坐标系中表示，则特征向量的分量表示坐标系的各个轴，由各个特征量具体
  的特征值得出的坐标系中的点，就是样本，而对各个样本进行画圈分类，则表示对样本进行分类，有两种分类；
<ol>
<li>确定性分类：表示每个样本点确定的只属于某个类别，不属于另一个类别，这样的分类具有明显的界限；
</li>
<li>随机性分类：表示某个样本点属于某个类别的概率为多少，该样本点也有可能属于另一个类别，属于另一个概率，通过比较各个概
     率值大小来判断该样本点属于哪个类别，一般这时候采用贝叶斯公式进行分类；
</li>
</ol>

</li>
<li>算术平均值：算术平均值是期望值的无偏估计量；
  $$ \overline{x} = \frac{x_{1}+...+x_{n}}{n} = \frac{\sum_{i=1}^{n}x_{i}}{n}$$
</li>
<li>均方根平均值： $$ \overline{x}=\sqrt{\frac{x_{1}^{2}+...+x_{n}^{2}}{n}}=\sqrt{\frac{\sum_{i=1}^{n}x_{i}^{2}}{n}}$$
</li>
<li>几何平均值： $$ \overline{x}=\sqrt[n]{x_{1}*...*x_{n}}=\sqrt[n]{\prod_{i=1}^{n}x_{i}}$$
</li>
<li>对数平均值: $$ \overline{x}=\frac{x_{1}-x_{2}}{\ln{x_{1}-\ln{x_{2}}}}$$
</li>
<li>加权平均值： $$ \overline{x}=\frac{w_{1}x_{1}+...+w_{n}x_{n}}{w_{1}+...+w_{n}}=\frac{\sum{w_{i}x_{i}}}{\sum{w_{i}}}$$
</li>
<li>残差：也叫剩余值，residual，表示实际值Y与回归线上的估计值Y'的纵向距离Y-Y', 一般Y'用E(Y)；
</li>
<li>SSE:和方差，是拟合数据和原始数据对应点的误差的平方和，SSE越接近于0，说明模型选择和拟合更好，数据预测也越成功。接下来的
  MSE和RMSE因为和SSE是同出一宗，所以效果一样, y<sub>i</sub>表示实际值， \(\widehat{y_{i}}\) 表示估计值，计算公式； 
  $$ SSE = \sum_{i=1}^{n}w_{i}(y_{i}-\widehat{y_{i}})^{2}$$
</li>
<li>MSE: 均方差，是预测数据和原始数据对应点误差的平方和的均值，也就是SSE/n，和SSE没有太大的区别，计算公式；
  $$ MSE = SSE/n$$
</li>
<li>RMSE:均方根，也叫回归系统的拟合标准差，是MSE的平方根，就算公式如下；
  $$ RMSE = \sqrt{MSE}$$
</li>
<li>SSR: Sum of squares of the regression，即预测数据与原始数据均值之差的平方和, \(\overline{y_{i}}\) 数据的平均值，公式如下
  $$ SSR=\sum_{i=1}^{n}w_{i}(\widehat{y_{i}}-\overline{y_{i}})^{2}$$
</li>
<li>SST：Total sum of squares，即原始数据和均值之差的平方和，公式如下；
  $$ SST=\sum_{i=1}^{n}w_{i}(y_{i}-\overline{y_{i}})^{2}$$ 
</li>
<li>R-square: 确定系数, 定义为SSR和SST的比值，取值范围为[0, 1],越接近1，表明方程的变量对y的解释能力越强，模型对数据拟合的
  越好，公式如下；
  $$ R-square = \frac{SSR}{SST}=\frac{SST-SSE}{SST}=1-\frac{SSE}{SST}$$
</li>
<li>最大似然估计： 似然估计是在每个事件x<sub>i</sub>的概率分布确定p(x<sub>i</sub>)，但是参数未知的情况下的一种估计方式，因为如果我们确定了
  这个参数，那么我们采集到的这些事件样本发生的概率应该最大，即p(x<sub>1</sub>)*&hellip;*p(x<sub>n</sub>)最大，具体解时可以采用log方式转换, 最
  大似然估计还可以这样理解，即，我们观察到的结果最容易是哪个因素引起的，比如手写识别时，就是要找出哪个单词最大概率导致出
  这个手写样本产生，最大似然代表最能满足样本的模型情况；要采用似然估计，必须满足一定条件；
<ol>
<li>事件x<sub>i</sub>的概率分布确定，这样待估参数是确定性的未知量；
</li>
<li>每个样本是独立的，这样才能使用概率乘法；
</li>
<li>如果待估参数是多维的，那么每个类别的样本x<sub>i</sub>，不包含另一个类别中信息；
</li>
</ol>

</li>
<li>奥卡姆剃刀：如果两个理论具有相似的解释力度，那么优先选择那个更简单的，因为，往往越简单越常见，越繁复越少见，一般代表先
  验概率最大的模型情况；
</li>
<li>损失函数：loss function，指我们的估计模型的输出值y与真实值之间的偏差，x是输入数据，y(x)是推测出结果的模型，t是x对应的
  真实结果，y(x)是t的估计值，则损失函数表示为L(t, y(x)), 我们常用的损失函数有平方差函数
  $$ L(t, y(x)) = [y(x)-t]^{2}$$ 通常在进行度量时，使用损失函数的平均值E(L)来衡量
  $$ E(L) = \iint L(t, y(x))p(y,x)\mathrm{d}x\mathrm{d}y$$ 
</li>
</ul>


</div>

</div>

<div id="outline-container-4-2" class="outline-3">
<h3 id="sec-4-2">贝叶斯分类</h3>
<div class="outline-text-3" id="text-4-2">

<p>可以通过一个例子先明确先验概率，后验概率的具体情况：如果有一所学校，有60%是男生和40%是女生。女生穿裤子与裙子的数量相同；
所有男生穿裤子。一个观察者，随机从远处看到一名学生，观察者只能看到该学生穿裤子。那么该学生是女生的概率是多少？这里题目中
观察者比如近似眼看直接不清性别，或者从装扮上看不出。答案可以用贝叶斯定理来算。
</p><ul>
<li>用事件 G 表示观察到的学生是女生；
</li>
<li>用事件 T 表示观察到的学生穿裤子；
</li>
</ul>

<p>于是，现在要计算 P(G|T) ，我们需要知道：
</p><ol>
<li>P(G) ：表示一个学生是女生的概率，这是在没有任何其他信息下的概率。这也就是我们说的先验概率。由于观察者随机看到一名学生，
   意味着所有的学生都可能被看到，女生在全体学生中的占比是 40 ，所以概率是 0.4 。
</li>
<li>P(B)：是学生不是女生的概率，也就是学生是男生的概率，也就是在没有其他任何信息的情况下，学生是男生的先验概率。 B 事件是
   G 事件的互补的事件，这个比例是 60 ，也即 0.6 。
</li>
<li>P(T|G)： 是在女生中穿裤子的概率，根据题目描述，是相同的 0.5 。这也是 T 事件的概率，given G 事件。
</li>
<li>P(T|B)： 是在男生中穿裤子的概率，这个值是1。
</li>
<li>P(T)： 是学生穿裤子的概率，即任意选一个学生，在没有其他信息的情况下，TA穿裤子的概率。如果要计算的话，那可以计算出所有
   穿裤子的学生的数量，除以总数，总数可以假设为常数 C ，但是最后会被约去。或者根据全概率公式 P(T)=P(T|G)P(G)+P(T|B)P(B)
   计算得到 P(T)=0.5×0.4+1×0.6=0.8 。 
</li>
</ol>

<p>基于以上所有信息，如果观察到一个穿裤子的学生，并且是女生的概率是P(G|T)=P(T|G)P(G)P(T)=0.5×0.40.8=0.25.
另一个例子关于手写识别，即我们采集到了用户输入的手写样本D，现在我们要计算用户最想输入哪个单词H，其中可能有h1,h2&hellip;hn, 那
么我们需要计算P(h<sub>i</sub>|D)的概率，哪个h<sub>i</sub>概率大，我们就可以说用户想输入哪个单词，对此，我们有如下公式，可以解释为
</p><ol>
<li>P(h<sub>i</sub>|D)：后验概率，在获得输入样本后，这个样本最大可能预示的单词；
</li>
<li>P(D|h<sub>i</sub>)：似然概率，某个单词可能导致出现这样的样本的概率，最大似然，也就意味着寻找这个最大概率的单词，可由训练得到；
</li>
<li>P(h<sub>i</sub>)：先验概率，某个单词出现的概率，也就是该单词在人们日常用语中出现的概率，可以通过语料库获得；
</li>
<li>P(D)：对于所有的单词预测，P(D)是一致的，可以视为常数，并且可以忽略，只需要比较后验概率*似然概率的相对大小；
</li>
</ol>


$$ P(h_{i}|D)=\frac{P(D|h_{i})*P(h_{i})}{P(D)}$$
<p>
另外根据不同的分类决策规则，贝叶斯分类有多种形式。
</p><ol>
<li>最小错误率贝叶斯分类器；
</li>
<li>最大似然比贝叶斯分类器；
</li>
<li>最小风险贝叶斯分类器；
</li>
</ol>


</div>

<div id="outline-container-4-2-1" class="outline-4">
<h4 id="sec-4-2-1">最小错误率贝叶斯分类器</h4>
<div class="outline-text-4" id="text-4-2-1">

<p>最小错误率贝叶斯分类器也可以叫最大后验概率分类器。
当已知类别出现的先验概率\(P(\omega_{i})\)和每个类中的样本分布的类条件概率密度\(P(x|omega_{i})\)时，可以求得一个待分类样本属于每
类的后验概率\(P(\omega_{i}|x)\), 将其划归到后验概率最大的那一类中，这种分类器称为最小错误率贝叶斯分类器，其分类决策规则可表
示为：
</p><ol>
<li>两类问题中，当\(P(\omega_{i}|x) &gt; P(\omega_{j}|x)\)时，判决\(x \in \omega_{i}\);
</li>
<li>对于多类情况，则当\( P(\omega_{i}|x)=\max\limits_{1\leq j \leq c} P(\omega_{j}|x)\)时，判决\(x\in \omega_{i}\)
</li>
</ol>

<p>可以发现，上述分类决策规则实为“最大后验概率分类器”，它与“最小错误率分类器”的关系可以简单分析如下：当采用最大后验概率
分类器时，分类错误的概率为
$$ P(e) = \int_{-\infty}^{-\infty}P(error, x)\mathrm{d}x$$  
而 $$ P(error|x) = \sum_{i=1}^{c}P(\omega_{j}|x) - \max\limits_{1\leq j\leq c}P(\omega_{j}|x) $$  因此，\(P(error|x)\)取
得了最小值， P(e)也取得了最小值，“最大后验概率分类器”与“最小错误率分类器”是等价的。
</p></div>

</div>

<div id="outline-container-4-2-2" class="outline-4">
<h4 id="sec-4-2-2">最大似然比贝叶斯分类器</h4>
<div class="outline-text-4" id="text-4-2-2">

<p>类条件概率\(P(x|\omega_{i})\)称为\(\omega_{i}\)对特征向量x的似然函数，表达了某类别中的样本取某特征值的可能性。由最小错误
率贝叶斯分类器可知，对于两类问题，当\(P(x|\omega_{i})*P(\omega_{i}) &gt; P(x|\omega_{j})*P(\omega_{j})\)时，判决
\(x\in\omega_{i}\) 即当 $$ \frac{P(x|\omega_{i})}{P(x|\omega_{j})} &gt; \frac{P(\omega_{j})}{P(\omega_{i})}$$ 时判决
\(x\in\omega_{i}\) ，那么下面式子称为 <span style="text-decoration:underline;">似然比</span> 。 $$ L_{ij}(x) = \frac{P(x|\omega_{i})}{P(x|\omega_{j})}$$
它与待识别的特征向量有关，而下面式子称为 <span style="text-decoration:underline;">判决门限</span> 。$$ \theta_{ij}=\frac{P(\omega_{j})}{P(\omega_{i})}$$
它仅与两类的先验概率有关；对于多类问题，分类决策规则为若 \(L_{ij}(x) &gt; \theta_{ij}\)对于任意的\(i，j=1,2...c, i\neq j\)
成立，则\(x\in \omega_{i}\)。 
</p></div>

</div>

<div id="outline-container-4-2-3" class="outline-4">
<h4 id="sec-4-2-3">最小风险贝叶斯分类器</h4>
<div class="outline-text-4" id="text-4-2-3">

<p>在最小错误率贝叶斯分类器分类器中，仅考虑了样本属于每一类的后验概率就做出了分类决策，而没有考虑每一种分类决策的风险。事实
上，在许多模式识别问题中，即时样本属于两类的后验概率相同，将其分到每一类中所带来的风险也会有很大差异。
例如针对某项检测指标进行癌症的诊断，如果计算出患者患癌症和未患癌症的后验概率均为 50%，如果患者真实情况是患了癌症，此时做出未患癌症的诊
断会延误治疗时机，比做出患癌症的诊断带来更为严重的后果。
因此，在获得样本属于每一类的后验概率后，需要综合考虑做出各种分类决策所带来的风险，选择风险最小的分类决策，称为最小风险贝叶斯分类器。
先定义以下几个概念：
</p><ol>
<li>决策\(\alpha_{i}\):把待识别样本x归到\(\omega_{i}\)中；
</li>
<li>损失\(\lambda_{ij}\):把真实属于\(\omega_{j}\)类的样本x归到\(\omega_{i}\)类中带来的损失；
</li>
<li>条件风险\(R(\alpha_{i}|x)\):对x采取决策\(\alpha_{i}\)后可能的风险；
</li>
</ol>

<p>条件风险可以用采取某项决策的加权平均损失来计算，权值为样本属于各类的概率，即
$$ R(\alpha_{i}|x)=E[\lambda_{ij}]=\sum_{j=1}^{c}\lambda_{ij}P(\omega_{j}|x),i=1,2...,c$$
则最小风险贝叶斯分流器的分类决策规则为
若
$$ R(\alpha_{k}|x) = \min\limits_{i=1,2...c}R(\alpha_{i}|x)$$ 
则
$$ x\in \omega_{k}$$ 
</p></div>

</div>

<div id="outline-container-4-2-4" class="outline-4">
<h4 id="sec-4-2-4">朴素贝叶斯</h4>
<div class="outline-text-4" id="text-4-2-4">

<p>朴素贝叶斯：是在贝叶斯分类基础上，基于一个简单的假定：给定目标值时属性之间相互条件独立，这样可以简化似然概率的计算。朴素
贝叶斯理论经典应用是垃圾邮件分类：给定一封邮件，判定它是否属于垃圾邮件。用D来表示这封邮件，注意D由N个单词组成。我们用h+
来表示垃圾邮件，h-表示正常邮件。问题可以形式化地描述为求：
$$ P(h+|D) = \frac{P(h+) * P(D|h+)}{P(D)}$$ 和
$$ P(h-|D) = \frac{P(h-) * P(D|h-)}{P(D)}$$ 
其中P(h+) 和P(h-)这两个先验概率都是很容易求出来的，只需要计算一个邮件库里面垃圾邮件和正常邮件的比例就行了。然而 P(D|h+)
却不容易求，因为D里面含有N个单词d<sub>i</sub>，所以
$$ P(D|h+) = P(d1,d2,..,dn|h+)$$ 
我们遇到了数据稀疏性，为什么这么说呢？P(d1,d2,..,dn|h+) 就是说在垃圾邮件当中出现跟我们目前这封邮件一模一样的一封邮件的概
率是多大！每封邮件都是不同的，世界上有无穷多封邮件, 计算起来会非常困难。我们又该如何来计算 P(d1,d2,..,dn|h+) 呢？
我们将 P(d1,d2,..,dn|h+) 扩展为： 
$$ P(d1|h+) * P(d2|d1, h+) * P(d3|d2,d1, h+) * .. $$
进一步使用一个更激进的假设，假设d<sub>i</sub> 与 d<sub>i-1</sub>是完全条件无关的，于是式子就简化为 
$$ P(d1|h+) * P(d2|h+) * P(d3|h+) * ..$$ 这个就是所谓的条件独立假设，也正是朴素贝叶斯方法的朴素之处。而计算该式子比较简
单，只要统计d<sub>i</sub>这个单词在垃圾邮件中出现的频率即可。
</p>
</div>
</div>
</div>
</div>
</div>

<div id="postamble">
<p class="date">Date: 2015-11-19 17:46:42 中国标准时间</p>
<p class="author">Author: 比克曼</p>
<p class="creator">Org version 7.8.11 with Emacs version 24</p>
<a href="http://validator.w3.org/check?uri=referer">Validate XHTML 1.0</a>

</div>
</body>
</html>
